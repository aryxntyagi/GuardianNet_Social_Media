GuardianNet: An AI-Based Safer Social Media Platform


GuardianNet is an AI-driven social media safety platform designed to detect and moderate harmful online content such as Fake News, Cyberbullying, and Hate Speech using Machine Learning (ML) and Natural Language Processing (NLP) techniques.


This project was developed as part of the Major Project (7th & 8th Semester) and focuses on building a lightweight, scalable, and practical solution for safer digital communication.


Features

Fake News Detection

Cyberbullying Detection

Hate Speech Detection

Confidence-based content classification

Unified web-based interface for testing and demonstration


Tech Stack

Programming Language: Python

Machine Learning: TF-IDF, Logistic Regression, XGBoost, BERT (experimental)

NLP Libraries: NLTK, Scikit-learn

Web Framework: Streamlit / Flask (as applicable)

Dataset Source: Kaggle (Fake News & Hate Speech datasets)


How It Works

User inputs text content into the system.

Text is preprocessed and converted into numerical features using TF-IDF.

Trained ML models classify the content as safe or harmful.

The system displays prediction results along with confidence scores.


Future Scope

Personalized content and safety recommendations

Multilingual text support

User authentication and database integration

Cloud deployment for real-world usage


(Future features are exploratory and subject to feasibility.)
